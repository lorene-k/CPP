                09/08
- operator can be attached to file name >> change lexer - OK
- TEST multiple heredocs - OK
- PB w/ single commd - OK
- check linked list if multiple redirections for 1 cmd - OK
- PB : flags - OK
- change makefile to put .c files in directories <<
- check how to get right return values <<
- expand exit codes in lexer - OK
>> PB : if no spaces, value doesn't expand

                02/08
- check how to merge "get_first" functions (with void * ?) <<
- implement linked list of files in case of multiple redirections - OK

                01/08
- test & parse whole line
    >> how to treat random string ? (ex : echo -n "hello") > infile - OK
    >> handle line w/ no redirect operators - OK
    >> test infile & outfile w/ no pipes - OK
- handle pipes - OK

                29/07
- token does not evolve outside of parser : added **token - OK
- fix check_cmd_args - OK
- check if files should be opened in parsing or exec >> just get names & open later : change parser_files - OK

                27-28/07
- fix invalid 1st str > error.c - OK
- TOKENIZER PBS : &'"é - OK 
- PB in lexer : cmd with args - OK
- do "if 1st token = str" case - OK

                22-23/07
- change back to rl_clear_history - OK
- check if file names needed in structs
- do get_cmd - OK
- handle errors <<<<<
- parsing planned : check 1st token, then parse to create cmd until eventual pipe in loop - OK

                21/07
- check that data->cmd points to 1st command in list - OK
- fix cmd init - OK

                20/07
- PB : unexisiting $VAR outputs nothing >> stay null - OK
- start parsing : parser_checker, parser_files, error
>> ADAPT get_files : change in & out for error messages - OK

                18/07
- PB : >> - OK
- FIX digit value - OK
- CHECK LEAKS - OK
- FIX quote pb (if no space between quote & char) get_str_value - OK
>> Norm tokenizer - about OK
>> Thoroughly test tokenizer before parsing - OK (test special cases)

                16/07
- PB w/ expand at end of unclosed quote - OK
>>>>>>> handle non expandable variables ($xxx)
- PB : DISSOCIATE IF IN QUOTES OR NOT TO EVENTUALLY CONSIDER CLOSING QUOTE - OK
- PB : $67 - OK
- fix empty quoted string >> segfault - OK
- check if i need to handle expansions within () - NOPE
- CHECK TYPES >> STR for non expandable expansions not in QUOTES - OK
- CHECK TYPES FOR EXPANDED VALUES NOT IN QUOTES - OK

                15/07
- PB : "é"§'ç!à&é" >> NON ASCII chars - OK
- PB w/ expansion in unclosed quotes - OK
- FIX LEXER_CHECK (segfaults) because 0 instead of *j - OK
>> do check quoted type - OK >> TEST

                12-14/07
- LOGIC PB : no check if strings are separated by spaces >> correct it by verifying before tokenizing
    >> for digits (check operator & punctuation) - OK
> if no space, value = string - OK
>> PB with check_quoted_input - OK
- PB with is_str flag in get_punctuation : set to 1 for '$' - OK
- PB : null tokens always created with type 2 = STR - OK
- PB : 1 null token always created (pb w/ loop ?) - OK (line = not null terminated str?)

                11/07
- expansion handled if unclosed quotes - OK
> handle multiple expansions if unclosed quotes >> loop - OK
>> TEST strategy n°2 (get_quoted_value) - OK
PB : nothing tokenized between expansions - OK

                07/07
OK - unclosed quote : parse nl ? (include in token ?)
OK - pb with make re : make: *** No rule to make target `objs', needed by `objs/clear.o'.
>> handle exit code expansion
>> THEN parse : CHECK IF VALID STRINGS, clean null tokens, create commands, handle redirections

                05/07
- handle var EXPANSION
    >> expand value - OK
    >> exit code <<
- handle unclosed quotes >> pb if multiple quotes (doesn't always give prompt back)
ex : "hello my name is" lorene" - OK
- check type for quoted strings
- protect mallocs !

                04/07
- started quote handling

                01/07
- FINISH LEXER
> handle var expansion
> handle quotes in tokens (if in quotes = 1 token)
>> specify each redirection type i token->type ?? 

                30/06
- ORDER PB : ///888 >> first / not tokenized
hellç; ;dpilkhdl)='= 
>> hell & scnd ; not tokenized
_ PROTECT ALL MALLOC : ft_substr & others

                28/06
- null token gets added at end of the list >> CHECK WHEN
- 7649832] : anything directly before specchar (no spaces) >> ok (order changed in lexer)

                27/06
- check lexer
- check linked lists - OK >> test clear
- handle non ascii values >> check if tokenize char/char or bulk by bulk
- PB WITH DATA->tokens
HANDLE TOKENS >> valgrind pb


TO DO

- ENV VARIABLE EXPANSION :
> traverse the linked list of tokens.
> For each token starting with $, replace it with the corresponding environment variable value BEFORE TOKENIZING

- PARSING:
> Create a linked list of command nodes
> For each token, determine if it is an argument, a redirection, or a pipe
> Construct command nodes accordingly and link them together

LEXER
- [ ] handle non ascii values
- [ ] handle comments
- [ ] checks

LOOP
- [ ] handle errors & exit codes
- [ ] add exec
- [ ] handle signals